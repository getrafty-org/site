<!DOCTYPE html>
<html lang="en" data-theme="light"><head><meta charSet="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="robots" content="index, follow"/><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><meta name="supported-color-schemes" content="light dark"/><meta name="theme-color" content="hsl(220, 20%, 100%)" media="(prefers-color-scheme: light)"/><meta name="theme-color" content="hsl(220, 20%, 10%)" media="(prefers-color-scheme: dark)"/><link rel="stylesheet" href="/static/main.css"/><link rel="stylesheet" href="/static/icomoon.css"/><link id="highlight-theme" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css"/><link rel="icon" type="image/png" sizes="32x32" href="/static/img/mascot.svg"/><title>Getrafty.org</title><meta name="description" content="Write-ups and exercises on distributed backend systems, offering an overview of the basic concepts. Whether you&#x27;ve been curious about how distributed file systems function or wanted to explore the inner workings of your favorite RPC framework, you&#x27;re in the right place. Here, you&#x27;ll have the opportunity to build a fully functional toy version yourself."/><meta name="keywords" content="distributed systems, backend systems, raft consensus algorithm, c++ exercises, rpc framework, distributed file systems, fault-tolerant systems, queues and thread pools, basic primitives, toy implementations of systems, distributed file server, remote procedure calls, distributed backend tutorials, contributing to distributed systems, basics of distributed systems, rafty exercises, getrafty, learn distributed systems, c++ exercises, file server exercises, scenes from distributed systems"/></head><body><header><nav class="navbar"><ul class="navbar-links"><li><button class="button theme-toggle"><a class="icon icon-magic" aria-hidden="true"></a></button></li><li><button class="button"><a class="icon icon-github" aria-hidden="true" href="https://github.com/getrafty-org" target="_blank" rel="noopener noreferrer"></a></button></li></ul></nav></header><main><a href="/index">cd ~/</a><h1>Basic primitives, Queues, Thread pools</h1>
<p>This is an introductory task where we touch on the concept of thread pool, the core component for scheduling and executing work in our distributed file system. <a href="https://en.wikipedia.org/wiki/Distributed_computing">Backend systems communicate by sending and receiving messages</a>, upon receiving a message the system typically runs some work. Modern hardware trending to <a href="https://homepages.inf.ed.ac.uk/bgrot/pubs/SOP_ISCA12.pdf">scale</a> much more through support of multiple cores rather than growing frequency of individual computation units.</p>
<p><img src="/static/img/scaling-cpu.png" alt="Scaling law"/></p>
<a data-component="ImgCap" href="https://www.researchgate.net/figure/Scaling-trends-for-the-transistor-count-clock-frequency-number-of-cores-and_fig2_224168227" class="img-cap">CPU Scaling Trends</a>
<p>To utilize the full capacity of the hardware we will run those callbacks on multiple cores / threads by scheduling them on the thread pool. For further task the thread pool will serve as a main infrastructure component for scheduling and executing work in parallel.</p>
<h2>Reusing Resources</h2>
<p>A thread pool is a programming concept that pre-allocates a set of reusable worker <a href="https://en.wikipedia.org/wiki/Thread_(computing)">threads</a> to execute tasks. Instead of creating a new thread for every task, the thread pool manages a queue of incoming tasks and assigns them to available threads, avoiding the overhead of frequent thread creation. Thread creation is a resource-intensive operation, consuming time and memory, especially when dealing with a high volume of tasks. By reusing threads, the thread pool reduces these costs and ensures efficient use of CPU and memory resources.</p>
<p>Common implementations of thread pools include JVM&#x27;s <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/util/concurrent/ExecutorService.html">ExecutorService</a>, Python&#x27;s <a href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor">concurrent.futures.ThreadPoolExecutor</a>, and C++&#x27;s <a href="https://github.com/facebook/folly/blob/main/folly/docs/Executors.md">Folly executors</a>.</p>
<p>There are multiple scheduling algorithms to organize work in the thread pool such as FIFO, <a href="https://en.wikipedia.org/wiki/Work_stealing">Work Stealing</a>, etc. In this task you&#x27;re suggested to implement the straightforward approach with a single shared queue for distributing load across multiple threads.</p>
<p><img src="/static/img/basic-thread-pool.png" alt="Basic thread pool"/></p>
<a data-component="ImgCap" href="https://en.wikipedia.org/wiki/Thread_pool" class="img-cap">Sample thread pool (green boxes) with waiting tasks (blue) and completed tasks (yellow)</a>
<h2>High-level Interface</h2>
<p>The main method of the <a href="https://github.com/getrafty-org/getrafty/blob/main/tasks/thread-pool/thread_pool.hpp"><code>ThreadPool</code></a> is <code>submit</code> which adds the task to the queue, and returns control back to the caller.  Methods <code>start</code> and <code>stop</code> are there for managing lifecycle of the pool and self-explanatory:</p>
<pre><code class="language-c++">using Task = std::function&lt;void()&gt;;

// Fixed-size pool of worker threads

class ThreadPool {
public:
    explicit ThreadPool(size_t threads);
    
    void start();
    bool submit(Task&amp;&amp;);
    void stop();
    
}
</code></pre>
<h2>Queue</h2>
<p>Our thread pool implementation will rely on a shared queue. Callers can add tasks to the queue using the <code>submit</code> method, while worker threads monitor the queue and pick up new tasks once they complete their current ones. But what happens when thereâ€™s no work available for a thread?</p>
<p>There are several strategies to handle this. One approach is to continuously retry, checking the queue until work appears. However, this can be inefficient, as it wastes CPU cycles on idle polling without providing any value. A more efficient alternative is to &quot;park&quot; the thread, taking it off the CPU until new tasks are available.</p>
<pre><code class="language-c++">// Unbounded blocking multi-producers/multi-consumers (MPMC) queue
template&lt;typename T&gt; 
class UnboundedBlockingQueue {
public:
    void put(T v);
    T take(); // This will block if queue is empty
}
</code></pre>
<p>The thread pool will rely on <a href="https://github.com/getrafty-org/getrafty/blob/main/tasks/thread-pool/queue.hpp"><code>UnboundedBlockingQueue</code></a>.</p>
<h2>ðŸ§  Task</h2>
<ul>
<li>You&#x27;re given a naive implementation of <code>UnboundedBlockingQueue</code> queue with <code>take</code> implementing a busy wait strategy, replace it with appropriate wait strategy without burning CPU cycles.</li>
<li>Implement <code>ThreadPool</code> class.</li>
</ul>
<h2>Verification</h2>
<p>Tests are located in <a href="https://github.com/getrafty-org/getrafty/blob/main/tasks/thread-pool/thread_pool_test.cpp"><code>thread_pool_test.cpp</code></a></p>
<div data-component="Oops"><p>Have questions? Check <a href="/etc/faq/">Q&amp;A</a> for most common issues or file an issue on the <a href="https://github.com/getrafty-org/getrafty/issues">GitHub</a>.</p></div></main><script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/bash.min.js"></script><script type="module" src="/static/main.js"></script></body></html>